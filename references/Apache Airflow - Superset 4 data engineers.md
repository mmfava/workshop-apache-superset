---
created: 2025-03-03T11:00
updated: 2025-03-03T11:07
link: https://www.youtube.com/watch?v=Mhai7sVU244&list=PLjyiM5wVnExRzkIWaYWDL768SAKmaIVR4
title: Advanced Apache Superset for Data Engineers
channel: Apache Airflow
---

# Transcrição

hi everyone so this is my second talk today my third talk at the airflow summit so now i i know the drill i'm ready for it and this one i'm really excited about so um today i'm talking about advanced apache superset for data engineers so um apache supersets i'll do a demo and you know uh kind of go through this and get to the agenda before before that i'm gonna introduce myself so this is the same slide i use um earlier this week at the keynote uh but i'll i'll essentially repeat very quickly and go through this so my name is max um i have just this this passion for building data tools so i started apache airflow back in 2014 while at airbnb i started apache superset just a little bit less than a year after as a originally that was a hackathon project that was a three-day hackathon at airbnb and more recently so about a year and a half ago excuse me i started a company called preset at preset.io and preset is a company that builds in and around apache superset we have a hosted offering of apache superset and we're uh we're doing all sorts of things around this space and analytics and some of which i'll uh i'll cover today cool so the agenda for today so i wanted to get into kind of deeper apache superset and show some more advanced features and things that data engineers or programmers can take advantage of so first i'm going to do a an overview quick overview and demo of supersets i think probably a lot of you guys have seen superset already but i'll do a very quick like five minutes just to show briefly what it looks like what it does and with a little bit more focus on the sql ide that we call sql lab so i'll focus on that and and some more advanced use cases for four data engineers um i will then talk about a feature that's not super well uh documented it is documented but it's it's a behind a feature flag it's not there by default that is around scheduling queries so there's a way that you can schedule your queries in superset and get airflow to pick up those queries and and schedule them and run them and weave them into dags it's pretty comfortable configurable so you can kind of make it work uh with the specificities of your environment we'll get into that um and then uh i'll show i'll give a few pointers as to how we build how to build visualization plugins so uh the superset platform is is extensible and you can write your own visualization it's a little bit involved but i'll show you how it works and that stuff is very well done now and well documented so i'll mostly just give pointers today and show you what's possible and the last item is i'll do a very quick demo of how we can build charts and dashboard dynamically so we have a rest api and there's uh there's other ways to to do it uh in superset using this equal alchemy um layer as well so i'll show i'll give you uh kind of an overview of how you can build charts dynamically so i think many of these things kind of relate to the work the kind of work that data engineers might want to do and some of them more directly you know relate to air flow like the scheduling feature uh the sql id kind of power features and uh building building chat charts and dashboard is something that you could think you would do to as part of more advanced uh data pipeline use cases right you could have a data pipeline that would um prepare excuse me prepare a custom dashboards or charts and drop them in some places cool so i'm going to pivot into the demo so i have not prepared a lot of time um so i'm going to kind of wing this demo and i'm just hoping that everything's going to go well i'm running off of my local here so here what i'm going to do is just show you a few things so superset is mostly three applications kind of into one or three main kind of vertical products inside of one the first one is the dashboard so here i'll pop a handful of dashboard that i'll show you just to give you an idea of the kind of the kind of dashboards that you can build in a superset and and here you see just a very simple dashboard um that has data of baby birth names in the u.s i'll show you very quickly the dashboard editor so as you pivot into this edit mode this is where you can come and add components like tabs rows headers markdown right so you can kind of integrate the things that you want and edit them and compose your dashboard however you'd like now i'll show you i'll close this window and go to um another dashboard right here looks like my laptop is slow i don't know what's dragging the cpu luckily i have a i'd just be able to go here and see what's going on here all right good so i wanted to leave this here all right cool so we're back um excellent so and i hear the cpu found on my laptop so i think it might be the software the light the the streaming software here cool so i'll show you a few things so here we have also like these interactive controls here where you can kind of apply dashboard apply filter to the dashboard we also have here i'll show you uh some of the the more fancy visualization with uh using a library called decgl here so um here we integrated while i worked at lyft and working with a team there at leaf lift we integrated some some more geospatial type visualization and some more advanced features so that shows you some of the features here i'm going to close some windows and then i will um pivot into a second part of the the app here excuse me all right so this um this app here is uh the explorer the place where you can go to slice and dice the data further so here you have a pointer to your table this is where you would you would pivot to different type of visualizations for instance so i might be interested in going to an area chart into the line chart i might want to instead of grouping by country i might be interested in grouping by a region um so it's a basic type of interactions you can also um adjust some of the more visual attribute of the visualization as to like whether you want uh for instance to use a log scale in place of a normal scale it looks like for the area chart that feature doesn't work cool um so here i wanted to show too that you can you can kind of browse the sql that's generated uh by superset to get to the data you can look at the results you can look at the properties of the charts uh but i'm going to stay shallow here and not do a too deep of a dive into some of these features i'll pivot into sql lab which we're going to do a slightly deeper dive into today so some of the things that are interesting about sql lab one is that we support templating and that this templating is compatible it uses the same templating engine as airflow which is a jinja 2. so so here it's possible to take queries that are arbitrarily complexed and and to set to pair parameterize them using some json so i'm going to show you some example of that before i jump into this i wanted to show just a little bit that we have an object browser here where you can kind of see your your tables um and browse their schemas so i think if uh if i get into let's see some of these tables if they have you know it will surface the metadata the index and that sort of thing so it's a pretty advanced sql ide where you can write arbitrarily complex query uh it's also possible to select kind of subsection of the sql and only run the selection which is pretty useful when you have a collection kind of a workbook with a lot of queries uh what i wanted to show now is a few more advanced features around templating so here maybe i'm going to make things a little bit bigger not too big for the sake of make sure everyone can can see what i'm doing here it makes the ui look a little bit bloated but but people are going to be able to see a little better so that's good um so here what do we have so we have a very simple query that's just a select there's no from uh and i have set a variable and and it's pretty easy for me to go and set other things i could say hello world and now that adds the second parameter here so now i should be able to add the variable that i added which was called hello and i should say world here so now we have a collection of things that have been defined here um there's just a string that's been defined just a normal sql and then we have some ginger templating that shows the variable pi and the variable lo the question is like where is this say hello coming from so one of the feature i wanted to show here as i pivot into my terminal is that here is my um superset config file so um in the in this superset config file goodness i've got some issues i've got a lag on my terminal my laptop is suffering i don't know what's going on it's just a little slow good all right um all right so um so here i wanted to show it's this little section here that i'm highlighting as i talk so uh there's a lambda that's defined here that's called say hello and it just does something extremely simple uh which is just saying hello um here you could easily add another lambda that would do something different so why is that interesting it's because in your in your environment you'll be able to define things that are specific to uh that might be interesting to you depending on on your needs and depending on what you do and your pipelines right so the fact that um the queries that you might bring into like in and out of airflow here use the same kind of living engine makes it kind of easy to test your things to to work in a more interactive place and to go back and forth cool so back into my presentation so that was the very quick demo and overview um and a deeper dive into sql lab and this is what i just showed you that you can in your superset config that's an environment a configuration variable define your own set of functions um now i'm going to talk about scheduling queries and that that feature has been behind a feature flag has been used at lyft for a while it's somewhat experimental but it works well i tested it before jumping into this demo briefly last night and it works very well so i'm going to show you today what it's all about so this feature was contributed by a committer named beeto that i worked with at life in the past um and it adds this section here that i'm highlighting and in there in the red square uh it adds a button that says schedule queries um and this is to satisfy the use case of like a lot of analysts might just uh craft some queries they don't necessarily want to work with source control or author their own dags sometimes you just want to have people go out there and schedule a query uh and you can do that uh fairly easily with superset so i'll show you um how it works and how to configure that and it's highly comfortable configurable which is kind of interesting so um in the documentation um so at this location here and i'll share the links and and the slides after the talk uh you'll see that uh it's well documented so if i click this link it's going to pop in my browser um and this is from the superset apache org documentation right and this uh everything that i'm going to talk about today is very well documented there thanks beto for documenting your work this is great and what you'll see is that you can define a json schema which in turns define the form that's going to pop inside superset so let me just show you the form here so when you click schedule query it will pop this form that you can you can fill in and this form is defined by you as the administrator of the system or the person who sets this up using this feature flag can define exactly how this feature is going to behave so here we say we want a title we want a description we want a collection of objects and we want for people to define the output table the start date the end date for the pipeline the schedule interval as well as the dependencies right and in your environment you might want to define the rules in a slightly different ways you might want to allow people to schedule only at certain intervals or to force a certain length to say like maybe only people can only schedule queries to operate for a certain number of days kind of more like the idea of a lease on a query so you don't have all this crap all these queries that are scheduled and and will run forever in your system so you define your rules you define what goes in this form in the context of lyft here um we had defined this idea of some uris that um people knew how to use um and it could be something like hey i want to wait on presto i want to wait on hive um so for for these dependencies it's an alternate way um in this case at lift we decided to go with a certain scheme in a certain pattern which may work or not work for you and the the thing that's kind of that you have to wrap your head around is that in this particular case superset does not do the scheduling it relies on this another scheduling engine to do to do the scheduling so let me just add this here so i'm going to add a quick description um and i'm going to say like this is the output table so this would be the table that this would go into and schedule interval might be daily i'm going to add a dependency on this hive table and say submit right so this has been saved and if i go into my save query here you'll see that this is the one that i just saved i'll delete the other one that was there from previous tests before and uh and there is a documented api endpoint here that you can hit to see the list of queries so this section here of this api endpoint is the exact metadata that's been defined dynamically in that form so that means now we can get airflow an airflow dag that will call this endpoint so it will call superset authenticate against it and say hello i'm airflow i would like to get the list of all the queries that i need to schedule and they will receive an object with this definition and process that object and schedule the queries so does that have to be airflow it could be something else it could be any other type of subsystem that can call an api and generate generate tasks cool so back to the presentation here it's also possible with these json schema to to do some sort of validation on the form uh it's possible to weave in some documentation so you can exactly tell people what they can and cannot do using these forms so that was my second uh feature or so here um and here are screenshots in case uh my laptop would struggle like it did earlier um next feature i'm going to talk about is this idea of building your own visualization plug-ins and what does that mean that means that anyone in superset today um that has a little bit of time on their hand and a fair amount of will can come here and create their own visualization so here i created two one called timeline one one called hello world um which is kind of the default that comes in the examples and this is the one we're gonna play with now the one called hello world so where do i start back to the slides here and i'll hit play again so um recently very recently so less than a week ago evan from preset published this blog post which explains exactly uh in great details how to build a a new visualization for superset and over the past i would say six months or so there's been a lot of work done in superset to to make the plug-in engine work very well so we had to essentially create the the interface for the plugins and make all the visualization that existed uh instead of being kind of tightly coupled uh visualizations that they were as part of the framework to cut them out and make them plug-ins too so that every visualization in super saiyan is a plug-in um and now i'm going to go a little bit into this blog post and kind of walk you through it so if you come to so this is our website preset.io under resources there's a blog and this is the blog post i'm talking about i will share that one in the notes and i'm sure you can find it pretty easily too so here um evan walks you in great detail um as to how to go step by step to create your visualization from setting up your superset environment all the way to generating a template so we use this thing called yeoman that that is a template generator engine and walks you through step by step um to create the set of templates so so you you follow these instructions and you get to a place where you have a new repository a new folder with a visualization that's this very basic hello world visualization that i have set up so it's a few steps and i've done these steps i can show you what it looks like so if i go back to let me close some windows here all right so yeah so if if i pivot to using one of these i will go to use the hello world one and i will run the query so it comes empty with really just something that says hello world and shows the data so it it comes already kind of pre-loaded um i'm hoping my setup is going to work a little bit better now so here i wanted to go into the hello world file and show you that this template has been generated by the template generator is loaded with instructions and comments that explain what every line of code here every section of the code does and it renders something really really simple which is this thing here and what we're looking at here is this section so i can show you very very quickly that i don't know i can i can add a new thing here that will say hello airflow summit save it and essentially wait a second and refresh the page and we're going to see the what i added here the thing that's really interesting about that is that um so this this is what i just added here the template here comes fully loaded with um well it comes loaded at the beginning with a certain set of controls that can you can easily kind of expand an augment right so here there's an example that shows like oh here there's a checkbox that says bold text and and it's attached somehow just to show the mechanics of how it works i'm sure if i look for bold text it's attached to this prop that is passed through the controls and it should be really easy for for anyone to just come here or for anyone that knows a little bit of of javascript and to add the controls that they want to kind of mutate this this um starting parameter this sandbox or the template into a much more complex data visualization right so from this point you can do something like import the data visualization library inside your plugin um and use it and connect it together so you could get something like d3 or get something like some sort of react visualization and bind it to your data pretty easily so what i wanted to show here is this file is where the controls are defined so i just wanted to show very easily here i had commented um this extra check box here that that i called a new checkbox and uh as soon as i as i reload this here we should have a new text box that's going to show up in this control panel right here it just shows you it's a it becomes almost like a very simple um um almost like platform and development environment to create new data visualization so what i wanted to show here is that we have this new um checkbox that's not bound to anything cool um so that gives you an idea of like how the mechanics of it work uh now i want to talk a little bit about what kind of use cases that could be used for and why that's kind of interesting and important so as i said like super said plug-in that that makes it that makes superset essentially an almost a data product development platform um in the context of superset you can uh you can you can build little data products uh without writing much backing code you can tap into superset data access layer so there's a lot going on behind the scene in superset to generate the queries talk to external databases like you know redshift bigquery snowflake whatever it might be doing that while doing authentication permissioning caching and audit so that's a lot that the superset backend does for you if you want to build a little data application data product you get all these rich controls at your fingertips i didn't really show you much here i showed you the checkbox but we have all sorts of color pickers and palette pickers and um you know these these like metric editors and all sorts of more advanced controls that you might want to use in your visualization like little sliders drop downs and things like that so those are your fingerprints they're really easy to use from the javascript content console or from the the javascript um [Music] plug-in you can really focus your work on the visualization the front-end work as opposed to any of the back-end code or interacting with data or crafting sql um and you can bring that visualization that you build inside a dashboard right so so that means that you could surround if you were to build i don't know let's say uh if you're at lyft and you're building a tool to show um how a specific ride went like maybe a ride to a ride player that would show a single ride and where the people went and all the events that happen in different geolocation like where the driver was and where the passenger was so you could build this little application from within some superset as a plug-in and bring it that into a dashboard where you could surround it with uh maybe line charts and bar charts and other things that that can be complementary right so because you're within that platform you have the full power of of everything else that's inside that platform so so we think and and i think that this is really interesting because you know these plugins now can be published as npm packages they can be shared across people um i'm really hoping that we start to see more specialized data visualization plugins show up for superset where people can exchange them so we can have this ecosystem of of plugins that people use and share and open source all right so the last um kind of example and little demo i'm going to cover today is this idea of dynamic charts and dashboard creation so the common way to go and create a chart or a dashboard and superchat is um to simply um to simply save it from here right you can just go and save this and get back to it so that's through the ui and similarly you know you can go and create a new dashboard charts in the ui but you can also do this programmatically so if you're in dev mode you can go to this endpoint called swagger do you want to get a sense of what's in our public rest api um so people at preset i've been working pretty hard at um at building so we always add this internal private api but now we've been working on a much more public api so that you can go and do uh the goal is like that so that everything you can do in the ui as a user you could do programmatically um through the rest api so what i wanted to show today is so swagger is this um i believe documentation framework around rest apis that allows people to define uh restful apis in a certain way and document them in a certain way and then this page can be embedded in your website to show exactly um it's an interactive documentation tool for your rest api um so here i'm looking at the chart endpoint so the get chart endpoint is where you would go to get a chart or a listed chart so here it gives you the query object and its structure and what i was going to do here is try to make it work just by using the swagger into interactive page here so if here if i just do an empty query and i click execute it's going to generate a curl this curl endpoint shows you again exactly what it looks like uh this is the request url and what it looks like when encoded and this is what the response looks like so the response got all sorts of information about like which columns that we query what are the labels the metadata around it and then it has the result that has a collection of charts so here this is the first chart here and this one i'm going to copy it and this one is called it's pointing to the data source energy usage and the the actual name of the chart is multi-line so i could go and kind of show you i'm just kind of in reality with what that looks like as i get back to it so this is this chart here it shows first here the same way it shows first and uh and and the rest uh response so now if i go and click this you're gonna see what this this chart looks like um it looks like it's a multi-charts it loads kind of two different things it's pretty busy not the best charts that we have in our examples but that will do and now that i've copied this i'm going to go towards our post endpoint here so this is a chart post endpoint and i believe i can click try it out and instead of using uh so this shows me the schema for i can just paste my um my my uh what i copied from the get endpoint now and i wanted to change the name so here um i'm going to call it again something hello airflow hello airflow and i believe i can just run this and i got uh the answer that i got looks like it was a bad request so i think i did something wrong here maybe um let's see what did i do wrong that look good to me well you know the demo goods are not always with us like there's probably an error somewhere in my in my um post here for the jason i'll try it again i mean i just got lucky when i did that last time i know i think actually it says chart added here this is the list of the answers i might get actually this is from the documentation so i think that i have gotten an answer this is just me not being good at uh swagging with swagger no it did not get created so something happened i could be debugging it but it shows you the mechanics of of how this all works right so you can essentially come here see the documentation for uh for for the the rest api see how that works try it out and that can help you kind of shape your uh your uh kind of your client or your script that you're gonna run to be able to do this um i think i'm not gonna fight with it here i tried that once yesterday and it worked i'm not sure why it's not working here fail to decode the json object so there's a bad delimiter here maybe someone in the cash question can point to me would i what i did wrong here uh but i will pass on it for now and get back to my slide so i think let's see we're getting closer to the end of this presentation we're 30 minutes in so i think the timing is pretty good um i wanted to show this other way too so another pointer is another alternate way to create charts and dashboard that is the improper not recommended way to do it um because it is more of the private api right so that would be using the sql alchemy models to do it um it's not recommended to do that as it's not guaranteed that it will work in future version right so it's gonna use at your own risk but i'll give the pointer to people in case people are interested on our github there is uh the examples that we load so when you first install superset you can run a command that's called superset load examples it will load a collection of examples and these this the code that does load the example is a viable and it's part of the superset package so this dashboard called birth names that we looked at before is loaded by this script here so it's pretty easy to go and reverse engineer how we load the data into the database and how we create a certain set of metrics uh and slices which are uh the the internal name for chart so here you can see that we create a certain number of charts in an array uh using some defaults using some some configuration as to like what is the from and what is the the time filtering what are the metrics what are uh the dimensions that we want to show um and in the end you know we create the actual dashboard for it which is a collection of the chart with positional um elements to it so it's something that you you might want to consider too if you're interested in building charts dynamically and if like for me the rest api they don't work for you um so that covers most of the material i wanted to cover the last uh the last slide is about uh the fact that uh we're hiring so the team appreciates growing we're about 25 people and we're looking to to grow pretty fast so and probably looking to hire our first data engineer we have mostly people working on like web development web application front and back and cloud infrastructure but we're also looking for um people for for at least one or two data engineers uh in in the next few months or so so please reach out and to that i will uh hand it back over to submit with the q a section uh oh awesome oh awesome this uh the superset looks uh pretty slick and interesting and uh i have actually we got couple of questions uh so we'll try to cover them and uh just a reminder if you have any questions uh like for the audience if you have any questions which is like unanswered or you you know uh caught up little late right then you can always ask into the slack channel um and we'll try to answer that there as well um okay so the first question we take is like uh so what would be the minimum uh system requirements to deploy it and test some of these features um so that's so that's that's that's a fairly hard question to answer but uh superset is a simple web application uh with the possibility of using some some async workers though that's that's optional so if you just want to test superset um you can do that very easily on a small machine like you don't really need to have um a very um you know like an array of machinery it's not a distributed system right superset is mostly just the consumption layer and really does uh does all the heavy listing in in your data warehouse or the source database that you're using so um it's really just all you need is to set up essentially you know a web server type of machine and if you have a lot of users like uh like the bigger installations uh you know your you can scale it out and have multiple web server machine put a load balancer in front of them uh but generally um super set doesn't take a lot of resources because the database that's behind it does the work okay so the next question is uh about the sql variant uh that used here is it that nc sql yes um yeah so let's let's talk about this a little bit so we have like technical people that know databases on the line so that i think that's going to be interesting so first um first thing is in sql lab um you write your sql and we pi we pass it to the database driver as it is and uh we we don't need to do too much uh that we'll just pass the sql along and get the response so we kind of sql dialect agnostic for sql lab itself now for the explore view which is the slice and dice part where you pick your metrics you pick your dimension you apply your filters what we do is we use a library called sql alchemy that probably many of you are if you if you're dealing with airflow you're probably familiar with it so it's a sql toolkit plus an rm on top right and the sql toolkit layer of sql alchemy speaks many dialects and it's pretty easy actually to write your own dialect so if you uh it's actually the case that uh some of my colleagues and uh beethoven lyft i think wrote the some of the sequel dialects for uh things like druid and for um and and for the google spreadsheet integration that we did so um so that's one of the way that's that superset knows how to speak sql now there are things that sql alchemy does not uh know about so it knows about dialect type things so that means it knows how to quote strings that knows whether to say limit or to say row num or top depending on the dialect that you use but it doesn't know all the date functions um and right like the date function date truncation function date subtraction addition function so we have a layer inside superset that uh that it's a module or package called db engine specs which for everything that is the database engine specific um and that deals with um putting all the databases at the same level so uh so so this the short answer that was a long answer the short answer is if there is a sql alchemy dialect for the database that you want to use most likely superset can talk to that database and we support a lot of databases and it's pretty easy to go and write your own dialect if needed that makes it such a you don't have to write it someone else probably did it because it's easy okay sounds great um okay so the next question is about about the superset operator for airflow so is it already exist or if not then uh people are asking like is there any chance to contribute one yes i think i might have uh i've written some in the past and superset operators you have to think about like what you want airflow to to get superset to do right so one thing that i talked about today is you might want airflow superset to create charts so that's an option uh which in which case it's pretty easy to just kind of post to uh the rest api uh but but one thing that we've done i think that i should have had in my talk but that's good that someone is asking the question now because that's that's a point of integration that's very common between the two that we had at both airbnb and lyft which is uh warming up the cache so when you write a pipeline so let's say you have a pipeline that loads up a table with rides information at lyft and that's a table that's used in a lot of dashboards and charts um superset as a caching engine i did not talk about that today but um it never got a cached adjacent payload that is behind each chart if you load the dashboard 100 charts behind the scene we we a hundred little json payloads with the data behind the chart so that when 100 people load that dashboard we don't hit the database um too much right we just hit the cache instead so um so there is a an end point in superset i can say you can call superset and say i just refresh this table the rights table go and refresh the cache for all the charts and dashboards that use this table so that the cache is always hot and and that airflow can kind of tell at which time to go uh and process that cache as opposed to adding something like the cache expiring and and sometimes hit or miss whether the data has been loaded or not loaded yet that can get a little tricky so i would highly recommend so if you're building superset dashboard on top of airflow tables loaded by airflow it's really easy to call that endpoint that's probably the reason why we don't have the operator just call an endpoint that says here's my table name and i i could i'll try to dig out the end point and share it in the notes okay uh sorry i think my skin looks frozen what is uh can you hear me max okay i think i'm back i'm here okay okay got it uh great so uh we can take maybe one or two questions more um so uh would it be uh and there would be some features like data source extract an is it in the sense of like a tableau extract or something like that it seems like that yeah yeah so so um so we made the very conscious decision uh with superset to not get into the the data the heavy kind of data compute database kind of data storage game superset is really in the consumption layer and i think that's a good thing so people nowadays make huge investments into their data warehouse right so uh you probably the the company you work at probably has made a huge investment in something like uh who knows presto snowflake uh hive druid uh redshift like whatever it may be and you have a big contract and you run this big database and you don't want to you know that's that's something that um you know you store all your data into your lake then you start your data into redshift and you store all your data into something like druid then you store all your data the same data again and uh in a tableau extract and um and and that introduces kind of latency etl things that can go wrong things that can be delayed so so we might we would much rather kind of not store data inside the superset layer and leave that to the data warehouse instead which is typically what we do what we recommend to do and these data warehouse typically do much better than the tableaux track can do right a database like druid can have billions and billions of rows and scan scan them under a second where you know at some point with a tablet extract and in my own experience uh that is a little bit data data with tableau when you get into the 100 millions of rows things typically get a little hard you have to deal with servers and this sort of thing so um so there we much rather you know hit your they hit your fast cash whatever it is whether it's a red ship or a druid or um or a snowflake nowadays okay okay sounds great and i think the last question uh that it is a web server based uh system so it should be able to host it on kubernetes completely there are elm charts around uh and we provide a docker um within our repository i think we store one we compute one at preset so if you look at the the docker hub for preset you'll find our docker um there is a helm chart i believe in the main um i think we have one in our repo now so we have i think the best elm chart you can find it's going to be that repo and i know there's one in the helm slash charts uh repo which is the central one with all the popular uh the most popular ones it's really easy to get going with that and then at some point if you have a larger install base you have to get a little bit deeper under the cover uh but super saiyan is fairly simple as as compared to airflow it's just collection of web servers uh we have a metadata database too we have these async workers with salary so it should sound pretty familiar to the airflow crowd actually awesome okay so yeah we are out of the time so thanks thanks a lot uh max for having uh this awesome session and for the audience i keep not uh if you have any other unanswered questions please use the slack channel and uh do not for forget to check the virtual swag bag at airportsummit.org and lastly if you wanted to revisit any of these stocks it will be available into the crowdcast itself just go and check out the recordings and yeah in 15 minutes we're gonna have uh awesome talk the next talk will be by qp and we're gonna talk about the how uh teaching an old day new tricks and that gonna happen to 15 minutes so it will be available in the same uh link where wherever you are right so you can just have a grab a tea coffee and then yeah see you in 15 minutes and thanks again max thank you very much pleasure.

# Resumo

## 1. Introdução

- **Palestrante:** Max
- **Contexto:**
    - Segundo (ou terceiro) talk em eventos como o Airflow Summit.
    - Experiência com ferramentas de dados: iniciou o Apache Airflow em 2014 (Airbnb) e o Apache Superset pouco tempo depois, também em ambiente de hackathon.
    - Atualmente, fundou a Preset, empresa que desenvolve soluções ao redor do Superset, incluindo oferta hospedada.

---

## 2. Agenda e Objetivos da Palestra

- **Foco da apresentação:**
    - Explorar recursos avançados do Apache Superset para data engineers e programadores.
- **Tópicos abordados:**
    - **Visão geral e demonstração do Superset:**
        - Interface, dashboards, visualizações e ênfase no SQL Lab.
    - **Agendamento de Queries:**
        - Funcionalidade escondida atrás de uma _feature flag_.
        - Integração com Airflow para agendar e executar queries.
    - **Criação de Plugins de Visualização:**
        - Desenvolvimento de visualizações personalizadas utilizando templates (ex.: “Hello World”).
    - **Criação Dinâmica de Dashboards:**
        - Utilização da API REST e Swagger para criar e gerenciar dashboards e gráficos de forma programática.

---

## 3. Demonstração do Apache Superset

### 3.1 Visão Geral da Interface

- **Dashboard:**
    
    - Possibilidade de criar dashboards personalizados com componentes como:
        - Tabs, linhas, cabeçalhos e componentes de markdown.
    - Exemplos apresentados, como o dashboard com dados de nomes de bebês nos EUA.
- **Explorer e SQL Lab:**
    
    - Ambiente para criar e explorar visualizações a partir de queries.
    - **SQL Lab:**
        - Suporte a queries complexas com templating (usando Jinja2 – o mesmo usado no Airflow).
        - Funcionalidades como execução de partes selecionadas do código SQL e navegação pelo _object browser_ para visualizar tabelas e metadados.

### 3.2 Funcionalidade de Templating e Configuração

- **Exemplo prático:**
    - Definição de variáveis e funções (lambdas) no arquivo de configuração do Superset.
    - Possibilidade de criar funções customizadas (ex.: “say_hello”) para uso em queries, facilitando testes e integração com pipelines.

---

## 4. Agendamento de Queries

- **Descrição:**
    - Funcionalidade experimental (atrás de _feature flag_) que permite agendar queries diretamente no Superset.
- **Como funciona:**
    - Interface com um botão “Schedule Query” que abre um formulário customizável.
    - O formulário é definido por um schema JSON, permitindo:
        - Definição de título, descrição, tabela de output, datas de início e fim, intervalo de agendamento e dependências.
- **Integração com Airflow:**
    - Airflow (ou outro agendador) pode chamar a API do Superset para obter as queries agendadas e integrá-las em DAGs.
    - Essa abordagem facilita a criação de pipelines que, por exemplo, geram dashboards atualizados automaticamente.

---

## 5. Criação de Plugins de Visualização

- **Objetivo:**
    - Permitir que desenvolvedores criem visualizações personalizadas para o Superset.
- **Ferramentas e Metodologia:**
    - Utilização de um gerador de templates (Yeoman) para iniciar o desenvolvimento.
    - Exemplo do “Hello World”:
        - Código gerado já vem com comentários e instruções para customização.
        - Integração de controles como checkboxes, color pickers, sliders, entre outros, para facilitar a interação e configuração da visualização.
- **Vantagens:**
    - Transforma o Superset em uma plataforma para desenvolvimento de “data products”.
    - Possibilidade de compartilhar os plugins via NPM e fomentar uma comunidade de visualizações customizadas.

---

## 6. Criação Dinâmica de Dashboards via API

- **API REST:**
    - Superset disponibiliza endpoints documentados (via Swagger) para:
        - Listar, criar e editar gráficos e dashboards.
    - Permite a criação programática de dashboards, similar à interface, mas através de chamadas de API.
- **Exemplo prático:**
    - Demonstração de consulta via GET e tentativa de criação de um novo gráfico via POST.
    - Nota: Durante a demo, ocorreram erros na criação via API, ilustrando desafios que podem surgir ao utilizar esse recurso em ambiente de desenvolvimento.

---

## 7. Perguntas & Respostas (Q&A)

- **Requisitos do sistema:**
    - Superset é uma aplicação web simples e pode ser testada em máquinas de baixo desempenho; a escalabilidade é possível com múltiplos servidores e load balancer.
- **SQL Dialect:**
    - Utiliza SQLAlchemy, que é agnóstico quanto ao dialeto SQL. Suporte a diversos bancos de dados (Presto, Snowflake, Hive, Druid, Redshift, etc.).
    - Para funções específicas (ex.: operações com datas), o Superset utiliza um módulo próprio (_db engine specs_).
- **Integração com Airflow:**
    - Existe a possibilidade de usar um operador (ou chamar endpoints) para, por exemplo, “aquecer” o cache dos dashboards após a atualização dos dados.
- **Data Source Extracts:**
    - Superset foi projetado para atuar como camada de consumo, utilizando o poder dos data warehouses modernos em vez de armazenar dados internamente.
- **Deploy em Kubernetes:**
    - Superset pode ser implantado em ambientes orquestrados, com suporte via Docker e Helm Charts disponíveis na comunidade e na própria Preset.

---

## 8. Considerações Finais

- **Recapitulação:**
    - A palestra abordou aspectos avançados do Apache Superset, destacando tanto funcionalidades já conhecidas (como o SQL Lab) quanto recursos mais inovadores (agendamento de queries, criação de plugins e dashboards dinâmicos via API).
- **Importância:**
    - O Superset se posiciona não apenas como uma ferramenta de visualização, mas como uma plataforma extensível para a criação de aplicações de dados e integração com pipelines de dados (como os do Airflow).
- **Próximos Passos:**
    - Explorar mais a fundo a documentação oficial e os exemplos disponíveis (ex.: repositório do Superset e blog posts da Preset) para entender a implementação de cada funcionalidade.
